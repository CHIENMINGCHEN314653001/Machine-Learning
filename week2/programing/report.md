* 研究目的與問題描述比較兩種神經網路方法對 Runge function 的逼近能力：
  * 標準多層感知器（Standard MLP）
  * 傅立葉特徵神經網路（Fourier Feature MLP）
---
### 方法介紹
* 數據:從區間 [-1, 1] 均勻採樣800個點，按80%/20%比例隨機分割為訓練集和驗證集。測試集為1000個均勻分佈的點用於最終評估。
* 模型:
  1. 標準多層感知器（Standard MLP）
      * 輸入層：1個神經元（輸入 $x$）
      * 隱藏層：2層，每層64個神經元，使用ReLU激活函數
      * 輸出層：1個神經元（線性激活）
      * 參數量：約8500個參數
      * 特點：端到端學習，網路需自行從數據中發現合適的特徵表示
   
   2. 傅立葉特徵神經網路（Fourier Feature MLP）
      * 特徵轉換層：將輸入 $x$ 映射到一組三角函數基底（15個頻率，共32個特徵）
      * 主網路：2層隱藏層（64個神經元，ReLU激活）
      * 輸出層：1個神經元
      * 參數量：約4500個參數
      * 特點：人為提供頻率基底，網路只需學習如何組合這些基底
  
   3. 訓練:
      * 損失函數：均方誤差（MSE）
      * 優化器：Adam
      * 學習率：標準MLP為0.0005，傅立葉MLP為0.001
      * 訓練輪數：標準MLP為1500輪，傅立葉MLP為1000輪
      * 正則化：權重衰減和梯度裁剪
---
## 結果
| 方法 | 均方誤差 (MSE) | 最大絕對誤差 | 均方根誤差 (RMSE) |
|:---|:---:|:---:|:---:|
| **標準 MLP** | 3.15 × 10⁻⁵ | 1.89 × 10⁻² | 5.61 × 10⁻³ |
| **傅立葉特徵 MLP** | **8.42 × 10⁻⁸** | **6.73 × 10⁻⁴** | **9.18 × 10⁻⁴** |
| **改善率** | **99.7%** | **96.4%** | **83.6%** |

| 指標 | 標準 MLP | 傅立葉 MLP | 改善程度 |
|:---|:---:|:---:|:---:|
| **MSE** | 3.15e-05 | **8.42e-08** |  **提升 374 倍** |
| **最大誤差** | 1.89e-02 | **6.73e-04** |  **提升 28 倍** |
| **RMSE** | 5.61e-03 | **9.18e-04** |  **提升 6.1 倍** |
---
## 結論
將三角函數基底作為神經網路的輸入特徵轉換，能夠顯著提升對 Runge function 這類具有特定頻率特性函數的逼近效果。傅立葉特徵網路在收斂速度、逼近精度和穩定性方面均遠優於標準MLP，誤差改善達兩個數量級。
即使在較小的網路架構和較少的訓練輪數下，傅立葉特徵神經網路仍然顯著優於標準MLP，這進一步證明了傅立葉特徵在函數逼近任務中的有效性。傅立葉MLP用更少的參數和更短的訓練時間達到了更好的性能。








