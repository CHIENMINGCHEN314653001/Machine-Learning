* 因 Backpropagation 在連續可微的狀態下執行，若改為「不連續」呢，如何設計有效的 Backpropagation 策略以確保梯度穩定且模型能順利收斂？
---
* 在眾多 activation function 中，未來會不會存在幾乎完美的激活函數呢?
---
* SGD 雖容易計算，但收斂數度慢、不穩定、鞍點問題等，不知道有沒有方法能改善?

